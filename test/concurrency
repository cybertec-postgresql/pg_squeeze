#!/usr/bin/python3
# # -*- coding: utf-8 -*-
#
# Copyright (c) 2016-2018, Cybertec Schönig & Schönig GmbH
#
# Test the squeeze_table() function while concurrent data changes. To verify
# that all the concurrent changes have been captured and processed, run the
# test once again w/o the squeeze_table() function and compare results.
#
# If the test should run for long time and if user suspects the tables can
# grow beyond disk space available, he can pass reasonable value of
# --test-duration and use --test-iterations option to ensure that the whole
# test (from table creation to verification of results) runs many times.

import argparse
import psycopg2
import random
import sys
import threading
import time
from threading import Thread, Timer

parser = argparse.ArgumentParser()
parser.add_argument("--host", default="localhost",
                    help="Database server host")
parser.add_argument("--port", default="5432",
                    help="Database server port")
parser.add_argument("--database", default="postgres",
                    help="The test database name")
parser.add_argument("--user", default="postgres",
                    help="The user that connects to the test database")
parser.add_argument("--test-duration", type=int, default=5,
                    help="Test duration in seconds")
parser.add_argument("--test-iterations", type=int, default=1,
                    help="How many times should the test be executed")
parser.add_argument("--no-verification", action="store_true",
                    help="Sikp verification of result, i.e. only test stability")
args = parser.parse_args()

test_succeeded = True

def get_connection():
    return psycopg2.connect(host=args.host, port=args.port,
                            database=args.database, user=args.user)

def start_single_test():
    d = globals()
    # All threads should check this variable and stop as soon as it becomes
    # True.
    d['test_done'] = False
    # Instead of letting the timer wait for the whole test time, we start it
    # many times for a 1-second interval so that user can interrupt the
    # application.
    d['timer_executions'] = 0
    # Since the test interval is one second, the number of executions is the
    # test duration in seconds
    d['timer_max_executions'] = args.test_duration

def stop_single_test(success):
    d = globals()
    d['test_done'] = True
    if not success:
        d['test_succeeded'] = False

# Stop if the required number of executions elapsed.
def maybe_stop_single_test():
    d = globals()
    d['timer_executions'] = d['timer_executions'] + 1
    if timer_executions >= timer_max_executions:
        stop_single_test(True)

def check(cur):
    # Check the pg_squeeze extension.
    cur.execute("SELECT extversion FROM pg_extension WHERE extname='pg_squeeze'")
    if cur.rowcount == 0:
        raise Exception("pg_squeeze is not installed")
    ext_row = cur.fetchone()
    d = globals()
    if ext_row[0] != "1.3":
        raise Exception("Unexpected pg_squeeze version: %s" % (ext_row[0],))

    # Make sure that the squeeze worker is off.
    cur.execute("SELECT squeeze.stop_worker()")

class CommandThread(Thread):
    def __init__(self, cmds, cmds_executed):
        super(CommandThread, self).__init__()
        self.cmds = cmds
        self.cmds_executed = cmds_executed

    def run(self):
        try:
            con = get_connection()
            # For debuging purposes we might need to print out XID, see below.
            con.autocommit = False
            cur = con.cursor()
            while not test_done:
                i = random.randint(0, len(self.cmds) - 1)
                next_cmd = self.cmds[i]
                cur.execute(next_cmd)
                # Get the transaction id.
                cur.execute("SELECT txid_current()")
                xid_row = cur.fetchone()
                con.commit()
                if self.cmds_executed != None:
                    # Record the command so it can be replayed during
                    # verification.
                    self.cmds_executed.append(i)
            con.close()
        except Exception as e:
            print(e)
            stop_single_test(False)

class SqueezeParams(object):
    def __init__(self, table, index):
        self.table = table
        self.index = index

class SqueezeThread(Thread):
    # params_array is an array of SqueezeParams instances
    #
    # delay is the number of seconds to wait before the next squeeze should
    # start.
    def __init__(self, params_array, delay):
        super(SqueezeThread, self).__init__()
        self.params_array = params_array
        self.delay = delay
        self.done = False

    def run(self):
        self.con = get_connection()
        self.con.autocommit = True
        self.cur = self.con.cursor()
        while not test_done:
            timer = Timer(self.delay, self.squeeze)
            timer.start()
            timer.join()
        self.con.close()
        self.done = True

    # Each call processes the next item of params_array (round robin).
    def squeeze(self):
        params = random.choice(self.params_array)
        try:
            ind = "'%s'" % params.index if params.index else "NULL"
            self.cur.execute(
                "SELECT squeeze.squeeze_table('public', '%s', %s, NULL, NULL)" %
                (params.table, ind,))
        except Exception as e:
            print(e)
            stop_single_test(False)

# cmds_setup is a list of commands to create the test table and any other
# database objects needed. The first item must be CREATE TABLE command, and it
# must contain two formatting strings: one to allow insertion of UNLOGGED
# keyword and one to insert schema name.
#
# cmds is a list of commands to be executed in random order. The commands must
# be such that new execution in the same order on an empty table produces the
# same results as during the first execution. For example, only stable
# functions (in terms of pg_proc(provolatile) may be used.
#
# check_query is an SQL query that compares the data produced by the stability
# test to the data produced by replaying the same commands and returns zero if
# the sets are identical.
class Test(object):
    def __init__(self, table, cmds_setup, cmds, check_query):
        self.table = table
        self.cmds_setup = cmds_setup
        self.cmds = cmds
        self.check_query = check_query

    def setup(self):
        con = get_connection()
        con.autocommit = True
        cur = con.cursor()
        cur.execute("DROP TABLE IF EXISTS %s" % self.table)
        first = True
        for cmd in self.cmds_setup:
            if first:
                # CREATE TABLE w/o the UNLOGGED keyword and with "public" as
                # schema name.
                cmd = cmd % ("", "public",)
                first = False
            cur.execute(cmd)
        con.close()
        if args.no_verification:
            self.cmds_executed = None
        else:
            self.cmds_executed = []

    def start(self):
        self.cmd_thread = CommandThread(self.cmds, self.cmds_executed)
        self.cmd_thread.start()

# Execute the test suite once.
def run_single_test(squeeze_thread):
    print('Running test...')
    start_single_test()

    for test in tests:
        test.setup()

    for test in tests:
        test.start()

    squeeze_thread.start()

    while True:
        if test_done:
            break
        timer = Timer(1, maybe_stop_single_test)
        timer.start()
        timer.join()

verification_schema = "expected"

# Run the same SQL statements on each table again, w/o the interference with
# squeeze_table(). The resulting tables should be identical.
def verify_single_test(squeeze_thread, con, con_vac):
    print("Verifying results...")
    cur = con.cursor()
    cur_vac = con_vac.cursor()

    # Make sure that the last call of squeeze_table() finished.
    while not squeeze_thread.done:
        time.sleep(1)

    cur.execute("CREATE SCHEMA IF NOT EXISTS %s" % verification_schema)
    con.commit()
    # Create tables to execute the queries again.
    for test in tests:
        cur.execute("DROP TABLE IF EXISTS expected.%s" % (test.table,))
        cur.execute(test.cmds_setup[0] % ("UNLOGGED", verification_schema,))
        # We try to run VACUUM FULL when it seems appropriate (see below), so do
        # not let autovacuum interfere with that effort.
        cur.execute("ALTER TABLE %s SET (autovacuum_enabled=false)" %
                    test.table)
        cur.execute("ALTER TABLE %s SET (toast.autovacuum_enabled=false)" %
                    test.table)
        con.commit()
        # Replay the commands. Use a separate transaction for each command and
        # change search_path only within the transaction so that we do not have to
        # remember the original value of search_path.
        rows = 0.0
        rows_live = 0.0
        for i in test.cmds_executed:
            cmd = test.cmds[i]
            cur.execute("SET LOCAL search_path TO expected")
            cur.execute(cmd)
            if cmd.lower().find('insert') >= 0:
                rows = rows + cur.rowcount
                rows_live = rows_live + cur.rowcount
            elif cmd.lower().find('update') >= 0:
                # UPDATE does not change the number of live rows, it just adds one
                # dead row per row updated.
                rows = rows + cur.rowcount
            elif cmd.lower().find('delete') >= 0:
                # DELETE removes a live row, but does not change the total number
                # of rows.
                rows_live = rows_live - cur.rowcount
            con.commit()
            # The check queries run much faster if the bloat is kept at reasonable
            # level.
            if rows > 0 and rows_live / rows < 0.5:
                cur_vac.execute("VACUUM FULL %s" % test.table)
                rows = rows_live

        # Compare the tables
        cur.execute(test.check_query)
        con.commit()
        if cur.rowcount == 0:
            print('Test passed for table "%s"' % test.table)
        else:
            print('Found difference for table "%s"' % test.table)

    con.close()
    con_vac.close()


tests = [
    Test(table = "a",
         cmds_setup = [
             "CREATE %s TABLE %s.a(i serial NOT NULL PRIMARY KEY, j int)",
         ],
         cmds = [
             "INSERT INTO a(j) SELECT g.i FROM generate_series(0, 255) AS g(i)",
             "UPDATE a SET j = j + 1 WHERE i IN (SELECT i FROM a WHERE i % 2 = 0 ORDER BY i LIMIT 256)",
             "UPDATE a SET j = j + 1 WHERE i IN (SELECT i FROM a WHERE i % 2 = 1 ORDER BY i LIMIT 256)",
             "DELETE FROM a WHERE i IN (SELECT i FROM a WHERE i % 2 = 0 ORDER BY i LIMIT 128)",
             "DELETE FROM a WHERE i IN (SELECT i FROM a WHERE i % 2 = 1 ORDER BY i LIMIT 128)"
         ],
         check_query = "SELECT * FROM public.a AS t1 FULL JOIN expected.a AS t2 ON (t1.i, t2.j) = (t2.i, t2.j) WHERE t1.i ISNULL OR t2.i ISNULL")
    ,

    # TOAST
    Test(table = "b",
         cmds_setup = [
             "CREATE %s TABLE %s.b(i serial NOT NULL PRIMARY KEY, j text)",
             "CREATE OR REPLACE FUNCTION public.long_string() RETURNS text LANGUAGE sql AS $$ SELECT string_agg(h.x::text, ' ') FROM generate_series(0, 4095) as h(x);$$"
         ],
         cmds = [
             "INSERT INTO b(j) SELECT public.long_string() FROM generate_series(0, 16) AS g(i)",

             "UPDATE b SET j = public.long_string() WHERE i IN (SELECT i FROM b WHERE i % 2 = 0 ORDER BY i LIMIT 256)",
             "UPDATE b SET j = public.long_string() WHERE i IN (SELECT i FROM b WHERE i % 2 = 1 ORDER BY i LIMIT 256)",

             "DELETE FROM b WHERE i IN (SELECT i FROM b WHERE i % 2 = 0 ORDER BY i LIMIT 8)",
             "DELETE FROM b WHERE i IN (SELECT i FROM b WHERE i % 2 = 1 ORDER BY i LIMIT 8)"
         ],
         check_query = "SELECT * FROM public.b AS t1 FULL JOIN expected.b AS t2 ON (t1.i, t2.j) = (t2.i, t2.j) WHERE t1.i ISNULL OR t2.i ISNULL")
    ,

    # Update identity key.
    Test(table = "c",
         cmds_setup = [
             "CREATE %s TABLE %s.c(i serial NOT NULL PRIMARY KEY, j real)"
         ],
         cmds = [
             # The values should be sparse so that the UPDATE can increment as
             # many values as possible.
             "WITH tmp(i) AS (SELECT max(i) FROM (SELECT i FROM c UNION VALUES (0)) AS s) INSERT INTO c SELECT g.i FROM tmp, generate_series(tmp.i + 1, tmp.i + 256) AS g(i)",

             # To avoid violation of the primary key, only update those rows
             # for which i + 1 does not exist.
             "UPDATE c SET i = i + 1 WHERE i IN (SELECT s1.x FROM (SELECT i, i + 1 FROM c) s1(x, y) LEFT JOIN (SELECT i FROM c) s2(x) ON s1.y = s2.x WHERE  s2.x ISNULL)",

             "DELETE FROM c WHERE i IN (SELECT i FROM c WHERE i % 2 = 0 ORDER BY i LIMIT 128)",
             "DELETE FROM c WHERE i IN (SELECT i FROM c WHERE i % 2 = 1 ORDER BY i LIMIT 128)",
         ],
         check_query = "SELECT * FROM public.c AS t1 FULL JOIN expected.c AS t2 ON t1.i = t2.i WHERE t1.i ISNULL OR t2.i ISNULL")
]

con = get_connection()
con.autocommit = True
cur = con.cursor()

try:
    check(cur)
    check_ok = True
except Exception as e:
    print(e)
    check_ok = False
finally:
    con.close()

if not check_ok:
    sys.exit(1)

for i in range(args.test_iterations):
    con = get_connection()
    con.autocommit = False

    # An extra connection for VACUUM because it cannot run inside transaction
    # block.
    con_vac = get_connection()
    con_vac.autocommit = True

    squeeze_thread = SqueezeThread(
        [
            SqueezeParams("a", None),
            SqueezeParams("a", "a_pkey"),
            SqueezeParams("b", None),
            SqueezeParams("b", "b_pkey"),
            SqueezeParams("c", None),
            SqueezeParams("c", "c_pkey")
        ],
        1.0)

    try:
        run_single_test(squeeze_thread)
    except KeyboardInterrupt as e:
        # Pay special attention to KeyboardInterrupt because the join() method
        # of Timer can be interrupted, in which case maybe_stop_single_test
        # never gets called.
        print(e)
        stop_single_test(False)
        con.close()
        con_vac.close()

    if test_succeeded:
        if not args.no_verification:
            try:
                verify_single_test(squeeze_thread, con, con_vac)
            except Exception as e:
                print(e)
                con.close()
                con_vac.close()
                sys.exit(1)
    else:
        con.close()
        con_vac.close()
        sys.exit(1)

